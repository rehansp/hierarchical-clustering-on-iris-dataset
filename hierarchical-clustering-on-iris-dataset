from sklearn import datasets, cluster
import matplotlib.pyplot as plt
import seaborn as sns

iris  = datasets.load_iris()

import scipy.cluster.hierarchy as sch
from sklearn.cluster import AgglomerativeClustering 

x = iris.data[:20,:2]
# x = iris.data[:10,:2]
y_iris = iris.target

print(x)
print(y_iris)

hc = AgglomerativeClustering(n_clusters=2, affinity = 'euclidean', linkage = 'ward') # affinity='euclidean': It is a metric used to compute the linkage.
# linkage='ward': It defines the linkage criteria, here we have used the "ward" linkage. This method is the popular linkage method that we have already used for creating the Dendrogram. It reduces the variance in each cluster.
y_hc = hc.fit_predict(x) # train the model
# plt.scatter(x[y_hc==0,0], x[y_hc==0,1], s = 10, c = 'red', label = 'cluster1') # creating cluster 1
# plt.scatter(x[y_hc==1,0], x[y_hc==1,1], s = 10, c = 'blue', label = 'cluster2') # creating cluster 2
# plt.show()

# creating dendrogram
dendrogram = sch.dendrogram(sch.linkage(x, method = 'ward'))
plt.show()
